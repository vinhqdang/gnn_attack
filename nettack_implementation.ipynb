{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Adversarial Attacks on Neural Networks for Graph Data (Nettack)\n",
                "\n",
                "This notebook implements the **Nettack** algorithm from the paper *Adversarial Attacks on Neural Networks for Graph Data* (KDD 2018) by ZÃ¼gner et al.\n",
                "\n",
                "## 0. Install Dependencies (Colab)\n",
                "Run this cell to install the necessary libraries in the Google Colab environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install PyTorch Geometric and dependencies\n",
                "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
                "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
                "!pip install -q torch-geometric\n",
                "!pip install -q matplotlib"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn.functional as F\n",
                "import numpy as np\n",
                "import scipy.sparse as sp\n",
                "from torch_geometric.datasets import Planetoid\n",
                "import torch_geometric.transforms as T\n",
                "from torch_geometric.nn import GCNConv\n",
                "from torch_geometric.utils import to_scipy_sparse_matrix, from_scipy_sparse_matrix\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Set device\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading\n",
                "\n",
                "We use the **Cora** dataset, a standard benchmark for graph neural networks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = Planetoid(root='/tmp/Cora', name='Cora', transform=T.NormalizeFeatures())\n",
                "data = dataset[0].to(device)\n",
                "\n",
                "# Convert to scipy sparse matrix for easier manipulation in Nettack\n",
                "adj = to_scipy_sparse_matrix(data.edge_index)\n",
                "features = data.x.cpu().numpy()\n",
                "labels = data.y.cpu().numpy()\n",
                "\n",
                "print(f'Dataset: {dataset}:')\n",
                "print('======================')\n",
                "print(f'Number of graphs: {len(dataset)}')\n",
                "print(f'Number of features: {dataset.num_features}')\n",
                "print(f'Number of classes: {dataset.num_classes}')\n",
                "\n",
                "print(f'Data object: {data}')\n",
                "print(f'Number of nodes: {data.num_nodes}')\n",
                "print(f'Number of edges: {data.num_edges}')\n",
                "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
                "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
                "print(f'Number of validation nodes: {data.val_mask.sum()}')\n",
                "print(f'Number of test nodes: {data.test_mask.sum()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Victim Model: Graph Convolutional Network (GCN)\n",
                "\n",
                "We implement a standard 2-layer GCN as the victim model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class GCN(torch.nn.Module):\n",
                "    def __init__(self, num_features, num_classes):\n",
                "        super(GCN, self).__init__()\n",
                "        self.conv1 = GCNConv(num_features, 16)\n",
                "        self.conv2 = GCNConv(16, num_classes)\n",
                "\n",
                "    def forward(self, x, edge_index):\n",
                "        x = self.conv1(x, edge_index)\n",
                "        x = F.relu(x)\n",
                "        x = F.dropout(x, training=self.training)\n",
                "        x = self.conv2(x, edge_index)\n",
                "        return F.log_softmax(x, dim=1)\n",
                "\n",
                "model = GCN(dataset.num_features, dataset.num_classes).to(device)\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
                "\n",
                "def train():\n",
                "    model.train()\n",
                "    optimizer.zero_grad()\n",
                "    out = model(data.x, data.edge_index)\n",
                "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
                "    loss.backward()\n",
                "    optimizer.step()\n",
                "    return loss.item()\n",
                "\n",
                "def test():\n",
                "    model.eval()\n",
                "    out = model(data.x, data.edge_index)\n",
                "    pred = out.argmax(dim=1)\n",
                "    accs = []\n",
                "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
                "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
                "    return accs\n",
                "\n",
                "print(\"Training GCN...\")\n",
                "for epoch in range(200):\n",
                "    loss = train()\n",
                "    if epoch % 20 == 0:\n",
                "        train_acc, val_acc, test_acc = test()\n",
                "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
                "\n",
                "train_acc, val_acc, test_acc = test()\n",
                "print(f'Final Test Accuracy: {test_acc:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Nettack Implementation\n",
                "\n",
                "Here we implement the Nettack algorithm. It involves:\n",
                "1.  **Surrogate Model**: Linearized GCN (SGC) for gradient estimation.\n",
                "2.  **Constraints**: Preserving degree distribution and feature co-occurrence.\n",
                "3.  **Attack**: Greedy selection of perturbations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Nettack:\n",
                "    def __init__(self, model, adj, features, labels, target_node, device='cpu'):\n",
                "        self.model = model\n",
                "        self.adj = adj.tolil() # Use LIL for efficient structure modifications\n",
                "        self.features = features.copy() # Numpy array\n",
                "        self.labels = labels\n",
                "        self.target_node = target_node\n",
                "        self.device = device\n",
                "        \n",
                "        # Surrogate model parameters (Linearized GCN)\n",
                "        # W1, W2 are from the trained GCN\n",
                "        self.W1 = model.conv1.lin.weight.detach().cpu().numpy().T\n",
                "        self.W2 = model.conv2.lin.weight.detach().cpu().numpy().T\n",
                "        self.W = self.W1.dot(self.W2)\n",
                "        \n",
                "        self.num_nodes = adj.shape[0]\n",
                "        self.num_features = features.shape[1]\n",
                "        \n",
                "        # Precompute A_hat^2 (approximate propagation)\n",
                "        self.adj_norm = self.normalize_adj(self.adj)\n",
                "        \n",
                "    def normalize_adj(self, adj):\n",
                "        # A_hat = D^-0.5 (A + I) D^-0.5\n",
                "        adj_aug = adj + sp.eye(adj.shape[0])\n",
                "        rowsum = np.array(adj_aug.sum(1))\n",
                "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
                "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
                "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
                "        return d_mat_inv_sqrt.dot(adj_aug).dot(d_mat_inv_sqrt).tocsr()\n",
                "\n",
                "    def compute_logits(self, adj_norm, features):\n",
                "        # Logits = A^2 X W\n",
                "        return adj_norm.dot(adj_norm).dot(features).dot(self.W)\n",
                "\n",
                "    def get_surrogate_loss(self, adj_norm, features, target_node, target_label):\n",
                "        logits = self.compute_logits(adj_norm, features)\n",
                "        logits_target = logits[target_node]\n",
                "        \n",
                "        # Softmax\n",
                "        probs = np.exp(logits_target) / np.sum(np.exp(logits_target))\n",
                "        return probs[target_label]\n",
                "\n",
                "    def attack(self, n_perturbations):\n",
                "        print(f\"Attacking node {self.target_node} (Class {self.labels[self.target_node]})...\")\n",
                "        \n",
                "        modified_adj = self.adj.copy()\n",
                "        \n",
                "        # Get initial prediction\n",
                "        adj_norm = self.normalize_adj(modified_adj)\n",
                "        initial_prob = self.get_surrogate_loss(adj_norm, self.features, self.target_node, self.labels[self.target_node])\n",
                "        print(f\"Initial Correct Class Probability (Surrogate): {initial_prob:.4f}\")\n",
                "        \n",
                "        for i in range(n_perturbations):\n",
                "            best_edge = None\n",
                "            best_prob = 1.0 # We want to minimize this\n",
                "            \n",
                "            # Greedy search over edges connected to target node (1-hop)\n",
                "            # In full Nettack, they search over all edges, but 1-hop is most effective usually.\n",
                "            candidates = []\n",
                "            \n",
                "            # Potential additions (connect target to others)\n",
                "            # Sample a subset of nodes to connect to (for speed)\n",
                "            potential_neighbors = np.random.choice(self.num_nodes, 50, replace=False)\n",
                "            for node in potential_neighbors:\n",
                "                if node != self.target_node and modified_adj[self.target_node, node] == 0:\n",
                "                    candidates.append((self.target_node, node, 1)) # Add edge\n",
                "            \n",
                "            # Potential deletions (remove existing edges)\n",
                "            neighbors = modified_adj[self.target_node].nonzero()[1]\n",
                "            for node in neighbors:\n",
                "                candidates.append((self.target_node, node, 0)) # Remove edge\n",
                "                \n",
                "            # Evaluate candidates\n",
                "            for u, v, action in candidates:\n",
                "                # Apply perturbation\n",
                "                if action == 1:\n",
                "                    modified_adj[u, v] = 1\n",
                "                    modified_adj[v, u] = 1\n",
                "                else:\n",
                "                    modified_adj[u, v] = 0\n",
                "                    modified_adj[v, u] = 0\n",
                "                \n",
                "                # Evaluate\n",
                "                adj_norm = self.normalize_adj(modified_adj)\n",
                "                prob = self.get_surrogate_loss(adj_norm, self.features, self.target_node, self.labels[self.target_node])\n",
                "                \n",
                "                if prob < best_prob:\n",
                "                    best_prob = prob\n",
                "                    best_edge = (u, v, action)\n",
                "                \n",
                "                # Revert perturbation\n",
                "                if action == 1:\n",
                "                    modified_adj[u, v] = 0\n",
                "                    modified_adj[v, u] = 0\n",
                "                else:\n",
                "                    modified_adj[u, v] = 1\n",
                "                    modified_adj[v, u] = 1\n",
                "            \n",
                "            if best_edge:\n",
                "                u, v, action = best_edge\n",
                "                if action == 1:\n",
                "                    modified_adj[u, v] = 1\n",
                "                    modified_adj[v, u] = 1\n",
                "                    print(f\"Step {i+1}: Added edge ({u}, {v}). New Prob: {best_prob:.4f}\")\n",
                "                else:\n",
                "                    modified_adj[u, v] = 0\n",
                "                    modified_adj[v, u] = 0\n",
                "                    print(f\"Step {i+1}: Removed edge ({u}, {v}). New Prob: {best_prob:.4f}\")\n",
                "            else:\n",
                "                print(\"No beneficial perturbation found.\")\n",
                "                break\n",
                "                \n",
                "        return modified_adj\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Experiment\n",
                "\n",
                "We select a target node and run the attack."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select a target node from the test set that is correctly classified with high confidence\n",
                "model.eval()\n",
                "out = model(data.x, data.edge_index)\n",
                "pred = out.argmax(dim=1)\n",
                "probs = torch.exp(out)\n",
                "\n",
                "target_node = -1\n",
                "for i in range(data.num_nodes):\n",
                "    if data.test_mask[i] and pred[i] == data.y[i] and probs[i, pred[i]] > 0.9:\n",
                "        target_node = i\n",
                "        break\n",
                "\n",
                "print(f\"Selected Target Node: {target_node}\")\n",
                "print(f\"True Label: {data.y[target_node].item()}\")\n",
                "print(f\"Initial Prediction: {pred[target_node].item()} (Conf: {probs[target_node, pred[target_node]]:.4f})\")\n",
                "\n",
                "# Initialize Nettack\n",
                "nettack = Nettack(model, adj, features, labels, target_node, device=device)\n",
                "\n",
                "# Run Attack (5 perturbations)\n",
                "modified_adj = nettack.attack(n_perturbations=5)\n",
                "\n",
                "# Evaluate on perturbed graph\n",
                "modified_edge_index, _ = from_scipy_sparse_matrix(modified_adj)\n",
                "modified_edge_index = modified_edge_index.to(device)\n",
                "\n",
                "model.eval()\n",
                "out_pert = model(data.x, modified_edge_index)\n",
                "pred_pert = out_pert.argmax(dim=1)\n",
                "probs_pert = torch.exp(out_pert)\n",
                "\n",
                "print(\"\\n--- After Attack ---\")\n",
                "print(f\"Prediction: {pred_pert[target_node].item()} (Conf: {probs_pert[target_node, pred_pert[target_node]]:.4f})\")\n",
                "if pred_pert[target_node] != data.y[target_node]:\n",
                "    print(\"SUCCESS: Attack flipped the label!\")\n",
                "else:\n",
                "    print(\"FAILURE: Label not flipped.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}